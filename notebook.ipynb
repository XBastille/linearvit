{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a1b2c3d4",
            "metadata": {},
            "source": [
                "# Task 2h: Linear Attention Vision Transformers for End-to-End Mass Regression and Classification\n",
                "\n",
                "**Author:** [Your Name]  \n",
                "**Task:** Specific Task 2h, GSoC 2026 ML4SCI / CMS End-to-End Deep Learning  \n",
                "**Repository:** [GitHub Link]\n",
                "\n",
                "---\n",
                "\n",
                "## Table of Contents\n",
                "\n",
                "1. [Overview and Approach](#1-overview-and-approach)\n",
                "2. [Architecture: Linear Attention ViT (L2ViT)](#2-architecture)\n",
                "3. [Self-Supervised Pretraining Strategy](#3-pretraining-strategy)\n",
                "4. [Setup: Dependencies and Data](#4-setup)\n",
                "5. [Training Process (Optional)](#5-training)\n",
                "6. [Model Definition and Weight Loading](#6-model-loading)\n",
                "7. [Test Set Evaluation](#7-evaluation)\n",
                "8. [Visualizations](#8-visualizations)\n",
                "9. [Discussion](#9-discussion)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2c3d4e5",
            "metadata": {},
            "source": [
                "## 1. Overview and Approach\n",
                "\n",
                "This notebook presents the solution for Task 2h: training a **linear-scale attention vision transformer** on CMS particle collision data for simultaneous binary classification and mass regression.\n",
                "\n",
                "### Task Requirements\n",
                "\n",
                "1. Train a linear-scale attention vision transformer.\n",
                "2. Pretrain on the unlabelled dataset, then finetune on the labelled dataset with a low learning rate.\n",
                "3. Compare the pretrained-then-finetuned model against a model trained from scratch.\n",
                "4. Use an 80/20 train/test split on the labelled data.\n",
                "\n",
                "### Approach Summary\n",
                "\n",
                "- **Architecture:** L2ViT (Linear-scale Attention Vision Transformer) with a Local Concentration Module (LCM), achieving $O(Nd^2)$ complexity via ReLU kernel-based attention.\n",
                "- **Pretraining:** SimCLR contrastive learning with physics-aware augmentations on the 28 GB unlabelled CMS dataset.\n",
                "- **Finetuning:** Dual-head model (classification + mass regression) with differential learning rates (lower backbone LR for pretrained, uniform LR for scratch).\n",
                "\n",
                "We initially explored Masked Autoencoder (MAE) pretraining. However, MAE degraded downstream performance compared to training from scratch (86.05% vs 89.45% accuracy). This is because the extreme sparsity of calorimeter images (98.8% zero pixels) causes the reconstruction objective to be dominated by trivially predicting background zeros. Additionally, MAE requires skipping the Local Concentration Module during pretraining (since masked tokens break the spatial grid for depthwise convolutions), leaving those weights randomly initialized during finetuning.\n",
                "\n",
                "SimCLR contrastive learning avoids both issues: it trains the full backbone including LCM, and its instance-discriminative objective focuses on learning features that distinguish different collision events rather than reconstructing empty space."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3d4e5f6",
            "metadata": {},
            "source": [
                "## 2. Architecture: Linear Attention ViT (L2ViT)\n",
                "\n",
                "The model follows the L2ViT architecture (Zheng et al., 2025), which replaces standard softmax attention with a linear-scale alternative.\n",
                "\n",
                "### Key Components\n",
                "\n",
                "| Component | Details |\n",
                "|---|---|\n",
                "| Patch Embedding | 5x5 patches from 125x125 images = 625 tokens |\n",
                "| Embedding Dimension | 256 |\n",
                "| Transformer Depth | 6 blocks |\n",
                "| Attention Heads | 4 (head_dim = 64) |\n",
                "| MLP Ratio | 4.0 |\n",
                "| LCM Kernel | 7x7 depthwise convolution |\n",
                "\n",
                "### Linear Attention\n",
                "\n",
                "Standard softmax attention has quadratic complexity: $O(N^2 d)$. Our linear attention uses a ReLU kernel to decompose the computation:\n",
                "\n",
                "$$\\text{Attn}(Q, K, V) = \\frac{\\phi(Q) \\cdot (\\phi(K)^T V)}{\\phi(Q) \\cdot (\\phi(K)^T \\mathbf{1})}$$\n",
                "\n",
                "where $\\phi(\\cdot) = \\text{ReLU}(\\cdot)$. By computing ${K^T V}$ first (a $d \\times d$ matrix), complexity reduces to $O(Nd^2)$.\n",
                "\n",
                "### Local Concentration Module (LCM)\n",
                "\n",
                "Each transformer block includes a depth-wise convolution (7x7 kernel) that provides local spatial context, compensating for the reduced expressiveness of linear attention compared to softmax attention. This is applied after the attention output within the residual connection.\n",
                "\n",
                "### Dual-Task Heads\n",
                "\n",
                "After mean-pooling the token sequence, two separate MLP heads produce:\n",
                "- **Classification logits** (2 classes: signal vs. background)\n",
                "- **Mass regression** (single scalar, trained with normalized targets)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d4e5f6g7",
            "metadata": {},
            "source": [
                "## 3. Self-Supervised Pretraining Strategy\n",
                "\n",
                "### SimCLR Contrastive Pretraining\n",
                "\n",
                "We pretrain the backbone using the NT-Xent (Normalized Temperature-scaled Cross Entropy) loss on the unlabelled CMS dataset (~57,000 images). Two independently augmented views of each image form a positive pair, while all other images in the batch serve as negative pairs.\n",
                "\n",
                "| Parameter | Value |\n",
                "|---|---|\n",
                "| Batch Size | 128 |\n",
                "| Learning Rate | 3e-4 |\n",
                "| Temperature | 0.5 |\n",
                "| Projection Dim | 128 |\n",
                "| Warmup Epochs | 5 |\n",
                "| Weight Decay | 0.05 |\n",
                "| Early Stopping | patience=15 |\n",
                "\n",
                "### Physics-Aware Augmentations\n",
                "\n",
                "The CMS detector images are in $(\\eta, \\phi)$ space, where $\\eta$ (pseudorapidity) is the vertical axis and $\\phi$ (azimuthal angle) is the horizontal axis. Our augmentations are chosen to respect the physical symmetries of the detector and collisions:\n",
                "\n",
                "| Augmentation | Physics Justification |\n",
                "|---|---|\n",
                "| Horizontal flip ($\\phi$-flip) | Azimuthal symmetry of the cylindrical CMS detector |\n",
                "| Vertical flip ($\\eta$-flip) | Approximate forward-backward symmetry of proton-proton collisions |\n",
                "| Cyclic roll along $\\phi$ | $\\phi$ is periodic (CMS is cylindrical); equivalent to viewing the collision from a different azimuthal angle |\n",
                "| Channel dropout (1-2 of 8) | Regularization simulating partial detector readout |\n",
                "| Gaussian noise on non-zero pixels | Simulates electronic noise in active calorimeter cells only; does not create unphysical artifacts in empty regions |\n",
                "\n",
                "We explicitly avoid augmentations that are appropriate for natural images but physically meaningless for calorimeter data: color jitter, aggressive random crops, Gaussian blur, and grayscale conversion. We also avoid 90-degree rotations, which would swap the $\\eta$ and $\\phi$ axes.\n",
                "\n",
                "After pretraining, the projection head is discarded and only backbone weights are saved for finetuning."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## 4. Setup: Dependencies and Data\n",
                "\n",
                "### 4.1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "538ec964",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: torch>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.8.0+cu128)\n",
                        "Requirement already satisfied: torchvision>=0.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.23.0+cu128)\n",
                        "Requirement already satisfied: timm>=0.9.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.0.25)\n",
                        "Requirement already satisfied: h5py>=3.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.15.1)\n",
                        "Requirement already satisfied: numpy>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
                        "Requirement already satisfied: scikit-learn>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.8.0)\n",
                        "Requirement already satisfied: matplotlib>=3.8.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.8.2)\n",
                        "Requirement already satisfied: seaborn>=0.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.13.2)\n",
                        "Requirement already satisfied: pandas>=2.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.1.4)\n",
                        "Requirement already satisfied: pyyaml>=6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (6.0.3)\n",
                        "Requirement already satisfied: tqdm>=4.66.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (4.67.3)\n",
                        "Requirement already satisfied: requests>=2.31.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (2.32.5)\n",
                        "Requirement already satisfied: tensorboard>=2.15.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.20.0)\n",
                        "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (3.20.3)\n",
                        "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (4.15.0)\n",
                        "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (80.10.2)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (1.14.0)\n",
                        "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (3.6.1)\n",
                        "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (3.1.6)\n",
                        "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (2026.1.0)\n",
                        "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.93)\n",
                        "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
                        "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.4.1)\n",
                        "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (11.3.3.83)\n",
                        "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (10.3.9.90)\n",
                        "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (11.7.3.90)\n",
                        "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.5.8.93)\n",
                        "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (0.7.1)\n",
                        "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (2.27.3)\n",
                        "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.90)\n",
                        "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (12.8.93)\n",
                        "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (1.13.1.3)\n",
                        "Requirement already satisfied: triton==3.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.2.0->-r requirements.txt (line 1)) (3.4.0)\n",
                        "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torchvision>=0.17.0->-r requirements.txt (line 2)) (12.1.0)\n",
                        "Requirement already satisfied: huggingface_hub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from timm>=0.9.0->-r requirements.txt (line 3)) (1.4.1)\n",
                        "Requirement already satisfied: safetensors in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from timm>=0.9.0->-r requirements.txt (line 3)) (0.7.0)\n",
                        "Requirement already satisfied: scipy>=1.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 6)) (1.11.4)\n",
                        "Requirement already satisfied: joblib>=1.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 6)) (1.5.3)\n",
                        "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 6)) (3.6.0)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (1.3.3)\n",
                        "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (4.61.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (1.4.9)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (25.0)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (3.3.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=2.1.0->-r requirements.txt (line 9)) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=2.1.0->-r requirements.txt (line 9)) (2025.3)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 12)) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 12)) (3.11)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 12)) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 12)) (2026.1.4)\n",
                        "Requirement already satisfied: absl-py>=0.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (2.4.0)\n",
                        "Requirement already satisfied: grpcio>=1.48.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (1.76.0)\n",
                        "Requirement already satisfied: markdown>=2.6.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (3.10.1)\n",
                        "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (6.33.5)\n",
                        "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (0.7.2)\n",
                        "Requirement already satisfied: werkzeug>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard>=2.15.0->-r requirements.txt (line 13)) (3.1.5)\n",
                        "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->-r requirements.txt (line 7)) (1.17.0)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.2.0->-r requirements.txt (line 1)) (1.3.0)\n",
                        "Requirement already satisfied: markupsafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.15.0->-r requirements.txt (line 13)) (3.0.3)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (1.3.1)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.28.1)\n",
                        "Requirement already satisfied: shellingham in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (1.5.4)\n",
                        "Requirement already satisfied: typer-slim in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.24.0)\n",
                        "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (4.12.1)\n",
                        "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.16.0)\n",
                        "Requirement already satisfied: typer>=0.24.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.24.1)\n",
                        "Requirement already satisfied: click>=8.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (8.3.1)\n",
                        "Requirement already satisfied: rich>=12.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (14.3.2)\n",
                        "Requirement already satisfied: annotated-doc>=0.0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.0.4)\n",
                        "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (4.0.0)\n",
                        "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (2.19.2)\n",
                        "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub->timm>=0.9.0->-r requirements.txt (line 3)) (0.1.2)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup_data_md",
            "metadata": {},
            "source": [
                "### 4.2. Download Datasets\n",
                "\n",
                "We require the **unlabelled dataset (28 GB)** for SimCLR pretraining, and the **labelled dataset (5 GB)** for finetuning and evaluation.\n",
                "\n",
                "**Note:** To skip the training process entirely and jump to evaluation with pre-trained weights, click here: [**Skip to Evaluation**](#7-evaluation)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "setup_data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset already exists: data/Dataset_Specific_Unlabelled.h5 (27.94 GB)\n",
                        "Dataset already exists: data/Dataset_Specific_labelled_full_only_for_2i.h5 (4.66 GB)\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import requests\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "DATA_DIR = os.path.join(os.path.dirname(os.path.abspath('.')), 'linearvit', 'data') \\\n",
                "    if not os.path.exists('data') else 'data'\n",
                "os.makedirs(DATA_DIR, exist_ok=True)\n",
                "\n",
                "DATASETS = {\n",
                "    \"unlabelled\": {\n",
                "        \"url\": \"https://cernbox.cern.ch/remote.php/dav/public-files/e3pqxcIznqdYyRv/Dataset_Specific_Unlabelled.h5\",\n",
                "        \"filename\": \"Dataset_Specific_Unlabelled.h5\",\n",
                "    },\n",
                "    \"labelled\": {\n",
                "        \"url\": \"https://portal.nersc.gov/cfs/m4392/G25/Dataset_Specific_labelled_full_only_for_2i.h5\",\n",
                "        \"filename\": \"Dataset_Specific_labelled_full_only_for_2i.h5\",\n",
                "    },\n",
                "}\n",
                "\n",
                "def download_file(url, dest_path, quiet=False):\n",
                "    if os.path.exists(dest_path):\n",
                "        file_size_gb = os.path.getsize(dest_path) / (1024**3)\n",
                "        if file_size_gb > 0.1:\n",
                "            if not quiet: print(f'Dataset already exists: {dest_path} ({file_size_gb:.2f} GB)')\n",
                "            return\n",
                "        else:\n",
                "            print(f'Dataset file appears corrupt ({file_size_gb:.4f} GB). Re-downloading...')\n",
                "            os.remove(dest_path)\n",
                "            \n",
                "    print(f'Downloading to {dest_path}...')\n",
                "    response = requests.get(url, stream=True, timeout=300)\n",
                "    response.raise_for_status()\n",
                "    total = int(response.headers.get('content-length', 0))\n",
                "    with open(dest_path + '.tmp', 'wb') as f, tqdm(\n",
                "        total=total, unit='iB', unit_scale=True, unit_divisor=1024, disable=quiet\n",
                "    ) as bar:\n",
                "        for chunk in response.iter_content(chunk_size=8192):\n",
                "            size = f.write(chunk)\n",
                "            bar.update(size)\n",
                "    os.rename(dest_path + '.tmp', dest_path)\n",
                "    if not quiet: print(f'Download complete: {dest_path}')\n",
                "\n",
                "# Download both datasets\n",
                "for key, ds in DATASETS.items():\n",
                "    dest_path = os.path.join(DATA_DIR, ds['filename'])\n",
                "    download_file(ds['url'], dest_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup_weights_md",
            "metadata": {},
            "source": [
                "### 4.3. Download Pre-trained Model Weights (Optional)\n",
                "\n",
                "If you want to skip training and directly evaluate, the cell below downloads the pre-trained model weights from the GitHub release. If the weight files already exist (e.g., from your own training), this step is automatically skipped.\n",
                "\n",
                "To skip the training step and jump directly to evaluation, [click here](#7-evaluation)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup_weights",
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Replace these URLs with your actual GitHub Release asset URLs after uploading\n",
                "RELEASE_BASE = 'https://github.com/YOUR_USERNAME/YOUR_REPO/releases/download/v1.0'\n",
                "\n",
                "WEIGHT_FILES = {\n",
                "    'weights/linear_vit_pretrained_finetuned.pt': f'{RELEASE_BASE}/linear_vit_pretrained_finetuned.pt',\n",
                "    'weights/linear_vit_scratch_finetuned.pt': f'{RELEASE_BASE}/linear_vit_scratch_finetuned.pt',\n",
                "}\n",
                "\n",
                "os.makedirs('weights', exist_ok=True)\n",
                "\n",
                "for local_path, url in WEIGHT_FILES.items():\n",
                "    if os.path.exists(local_path):\n",
                "        print(f'[EXISTS] {local_path} ({os.path.getsize(local_path) / 1024**2:.1f} MB)')\n",
                "    else:\n",
                "        print(f'[DOWNLOAD] {local_path} ...')\n",
                "        try:\n",
                "            r = requests.get(url, stream=True, timeout=120)\n",
                "            r.raise_for_status()\n",
                "            with open(local_path, 'wb') as f:\n",
                "                for chunk in r.iter_content(chunk_size=8192):\n",
                "                    f.write(chunk)\n",
                "            print(f'  Saved: {local_path} ({os.path.getsize(local_path) / 1024**2:.1f} MB)')\n",
                "        except Exception as e:\n",
                "            print(f'  Failed to download: {e}')\n",
                "            print(f'  Please download manually from the GitHub Release and place in weights/')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6g7h810",
            "metadata": {},
            "source": [
                "<a id='5-training'></a>\n",
                "## 5. Training Process (Optional)\n",
                "\n",
                "The training process consists of three major steps. The commands below execute the relevant python scripts from the `src/training` module. They use the `.yaml` configurations defining hyper-parameters and paths.\n",
                "\n",
                "**Note:** If you have already downloaded the pre-trained weights in step 4.3, you can skip this section entirely and proceed to evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "h8i9j011",
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAIN_MODELS = False  # Set to True if you wish to run the training cells below"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "i9j0k112",
            "metadata": {},
            "outputs": [],
            "source": [
                "if TRAIN_MODELS:\n",
                "    print(\"Starting SimCLR Pretraining on the unlabelled dataset...\")\n",
                "    !python -m src.training.pretrain_simclr --config configs/pretrain_simclr.yaml\n",
                "else:\n",
                "    print(\"Skipping SimCLR Pretraining.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "j0k1l213",
            "metadata": {},
            "outputs": [],
            "source": [
                "if TRAIN_MODELS:\n",
                "    print(\"Starting Finetuning using the SimCLR pretrained backbone...\")\n",
                "    !python -m src.training.finetune --config configs/finetune.yaml\n",
                "else:\n",
                "    print(\"Skipping Finetuning.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "k1l2m314",
            "metadata": {},
            "outputs": [],
            "source": [
                "if TRAIN_MODELS:\n",
                "    print(\"Starting Training from Scratch (random initialization)...\")\n",
                "    !python -m src.training.finetune --config configs/scratch.yaml\n",
                "else:\n",
                "    print(\"Skipping Scratch Training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6g7h8i9",
            "metadata": {},
            "source": [
                "<a id='6-model-loading'></a>\n",
                "## 6. Model Definition and Weight Loading\n",
                "\n",
                "We load the pretrained-then-finetuned model and the scratch-trained model to evaluate both on the held-out test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "g7h8i9j0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import numpy as np\n",
                "import torch\n",
                "import matplotlib\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import (\n",
                "    roc_auc_score, roc_curve, auc,\n",
                "    accuracy_score, mean_absolute_error,\n",
                "    confusion_matrix\n",
                ")\n",
                "\n",
                "sys.path.insert(0, os.path.abspath('.'))\n",
                "\n",
                "from src.models.linear_vit import LinearViT\n",
                "from src.data.dataset import CMSLabelledDataset, create_splits\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {device}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "h8i9j0k1",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model():\n",
                "    \"\"\"Construct the L2ViT model with the architecture used in training.\"\"\"\n",
                "    return LinearViT(\n",
                "        in_channels=8,\n",
                "        img_size=125,\n",
                "        patch_size=5,\n",
                "        embed_dim=256,\n",
                "        depth=6,\n",
                "        num_heads=4,\n",
                "        mlp_ratio=4.0,\n",
                "        num_classes=2,\n",
                "        drop_rate=0.1,\n",
                "        drop_path_rate=0.1,\n",
                "        lcm_kernel=7,\n",
                "    ).to(device)\n",
                "\n",
                "\n",
                "def load_model(ckpt_path):\n",
                "    \"\"\"Build model and load checkpoint weights. Returns model + checkpoint metadata.\"\"\"\n",
                "    model = build_model()\n",
                "    assert os.path.exists(ckpt_path), f'Checkpoint not found: {ckpt_path}\\nRun training or download weights first!'\n",
                "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
                "    model.load_state_dict(ckpt['model_state_dict'])\n",
                "    model.eval()\n",
                "    print(f'Loaded: {ckpt_path}')\n",
                "    return model, ckpt\n",
                "\n",
                "\n",
                "pretrained_model, pt_ckpt = load_model('weights/linear_vit_pretrained_finetuned.pt')\n",
                "scratch_model, sc_ckpt = load_model('weights/linear_vit_scratch_finetuned.pt')\n",
                "\n",
                "mass_mean_pt = pt_ckpt.get('mass_mean', 0.0)\n",
                "mass_std_pt = pt_ckpt.get('mass_std', 1.0)\n",
                "mass_mean_sc = sc_ckpt.get('mass_mean', 0.0)\n",
                "mass_std_sc = sc_ckpt.get('mass_std', 1.0)\n",
                "\n",
                "print(f'Pretrained mass normalization: mean={mass_mean_pt:.2f}, std={mass_std_pt:.2f}')\n",
                "print(f'Scratch mass normalization:    mean={mass_mean_sc:.2f}, std={mass_std_sc:.2f}')\n",
                "\n",
                "total_params = sum(p.numel() for p in pretrained_model.parameters())\n",
                "print(f'Total model parameters: {total_params:,}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_pipeline_md",
            "metadata": {},
            "source": [
                "### Data Pipeline\n",
                "\n",
                "The labelled dataset (10,000 images) is split deterministically with `seed=42`:\n",
                "\n",
                "| Split | Size | Usage |\n",
                "|---|---|---|\n",
                "| Train | 7,000 | Model training |\n",
                "| Validation | 1,000 | Early stopping, model selection |\n",
                "| Test | 2,000 | Final evaluation (touched once, after training completes) |\n",
                "\n",
                "The test set is never used for model selection or hyperparameter tuning."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "i9j0k1l2",
            "metadata": {},
            "source": [
                "<a id='7-evaluation'></a>\n",
                "## 7. Test Set Evaluation\n",
                "\n",
                "We evaluate both models on the identical held-out 20% test split (2,000 samples). The test set was created using `seed=42` and is never used during training or model selection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "j0k1l2m3",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = 'data/Dataset_Specific_labelled_full_only_for_2i.h5'\n",
                "splits = create_splits(data_path, seed=42)\n",
                "test_dataset = CMSLabelledDataset(data_path, indices=splits['test'], augment=False)\n",
                "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
                "\n",
                "print(f'Test set size: {len(test_dataset)} samples')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "k1l2m3n4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, loader, mass_mean, mass_std):\n",
                "    \"\"\"\n",
                "    Run inference on a DataLoader and collect predictions.\n",
                "    Returns dict with predictions, probabilities, labels, and mass values.\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    all_preds, all_probs, all_labels = [], [], []\n",
                "    all_mass_pred, all_mass_true = [], []\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for imgs, cls_labels, mass_labels in loader:\n",
                "            imgs = imgs.to(device)\n",
                "            cls_logits, mass_pred = model(imgs)\n",
                "\n",
                "            probs = torch.softmax(cls_logits, dim=1)[:, 1].cpu().numpy()\n",
                "            preds = cls_logits.argmax(dim=1).cpu().numpy()\n",
                "            mass_pred_real = (mass_pred.cpu().numpy().flatten() * mass_std) + mass_mean\n",
                "\n",
                "            all_preds.extend(preds)\n",
                "            all_probs.extend(probs)\n",
                "            all_labels.extend(cls_labels.numpy())\n",
                "            all_mass_pred.extend(mass_pred_real)\n",
                "            all_mass_true.extend(mass_labels.numpy())\n",
                "\n",
                "    return {\n",
                "        'preds': np.array(all_preds),\n",
                "        'probs': np.array(all_probs),\n",
                "        'labels': np.array(all_labels),\n",
                "        'mass_pred': np.array(all_mass_pred),\n",
                "        'mass_true': np.array(all_mass_true),\n",
                "    }\n",
                "\n",
                "\n",
                "print('Evaluating pretrained model...')\n",
                "pt_results = evaluate_model(pretrained_model, test_loader, mass_mean_pt, mass_std_pt)\n",
                "\n",
                "print('Evaluating scratch model...')\n",
                "sc_results = evaluate_model(scratch_model, test_loader, mass_mean_sc, mass_std_sc)\n",
                "\n",
                "print('Done.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "l2m3n4o5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(results):\n",
                "    \"\"\"Compute all evaluation metrics from model results.\"\"\"\n",
                "    acc = accuracy_score(results['labels'], results['preds'])\n",
                "    auc_score = roc_auc_score(results['labels'], results['probs'])\n",
                "    mae = mean_absolute_error(results['mass_true'], results['mass_pred'])\n",
                "    mse = float(np.mean((results['mass_pred'] - results['mass_true'])**2))\n",
                "    return {'Accuracy': acc, 'ROC-AUC': auc_score, 'Mass MAE (GeV)': mae, 'Mass MSE': mse}\n",
                "\n",
                "\n",
                "pt_metrics = compute_metrics(pt_results)\n",
                "sc_metrics = compute_metrics(sc_results)\n",
                "\n",
                "print()\n",
                "print('=' * 65)\n",
                "print(f'{\"Metric\":<20} {\"Pretrained (SimCLR)\":>20} {\"Scratch\":>20}')\n",
                "print('=' * 65)\n",
                "for key in pt_metrics:\n",
                "    pt_val = pt_metrics[key]\n",
                "    sc_val = sc_metrics[key]\n",
                "    print(f'{key:<20} {pt_val:>20.4f} {sc_val:>20.4f}')\n",
                "print('=' * 65)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "m3n4o5p6",
            "metadata": {},
            "source": [
                "### Expected Results\n",
                "\n",
                "The pretrained model is expected to outperform the scratch model across all metrics, demonstrating that self-supervised pretraining on unlabelled CMS data produces transferable representations that benefit both classification and mass regression tasks. The table above should show consistent improvements in accuracy, AUC, and mass regression error."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "n4o5p6q7",
            "metadata": {},
            "source": [
                "<a id='8-visualizations'></a>\n",
                "## 8. Visualizations"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz_cm_header",
            "metadata": {},
            "source": [
                "### 8.1. Confusion Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "o5p6q7r8",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "for ax, results, title in [\n",
                "    (axes[0], pt_results, 'Pretrained (SimCLR)'),\n",
                "    (axes[1], sc_results, 'Scratch'),\n",
                "]:\n",
                "    cm = confusion_matrix(results['labels'], results['preds'])\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
                "                xticklabels=['Class 0', 'Class 1'],\n",
                "                yticklabels=['Class 0', 'Class 1'])\n",
                "    ax.set_xlabel('Predicted')\n",
                "    ax.set_ylabel('True')\n",
                "    ax.set_title(f'Confusion Matrix: {title}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz_roc_header",
            "metadata": {},
            "source": [
                "### 8.2. ROC Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "p6q7r8s9",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(7, 7))\n",
                "\n",
                "for results, label in [\n",
                "    (pt_results, 'Pretrained (SimCLR)'),\n",
                "    (sc_results, 'Scratch'),\n",
                "]:\n",
                "    fpr, tpr, _ = roc_curve(results['labels'], results['probs'])\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    ax.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.4f})', linewidth=2)\n",
                "\n",
                "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
                "ax.set_xlabel('False Positive Rate')\n",
                "ax.set_ylabel('True Positive Rate')\n",
                "ax.set_title('ROC Curves: Pretrained vs Scratch')\n",
                "ax.legend(loc='lower right')\n",
                "ax.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz_mass_header",
            "metadata": {},
            "source": [
                "### 8.3. Mass Regression: Predicted vs True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "q7r8s9t0",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "for ax, results, title in [\n",
                "    (axes[0], pt_results, 'Pretrained (SimCLR)'),\n",
                "    (axes[1], sc_results, 'Scratch'),\n",
                "]:\n",
                "    ax.scatter(results['mass_true'], results['mass_pred'], alpha=0.3, s=8, c='steelblue')\n",
                "    lims = [\n",
                "        min(results['mass_true'].min(), results['mass_pred'].min()),\n",
                "        max(results['mass_true'].max(), results['mass_pred'].max()),\n",
                "    ]\n",
                "    ax.plot(lims, lims, 'r--', linewidth=1.5, label='Ideal Fit')\n",
                "    ax.set_xlabel('True Mass (GeV)')\n",
                "    ax.set_ylabel('Predicted Mass (GeV)')\n",
                "    ax.set_title(f'Mass Regression: {title}')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "r8s9t0u1",
            "metadata": {},
            "source": [
                "### 8.4. Training Curves\n",
                "\n",
                "Training and validation curves for both models, loaded from the checkpoint history."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "s9t0u1v2",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "for ckpt, label in [(pt_ckpt, 'Pretrained'), (sc_ckpt, 'Scratch')]:\n",
                "    hist = ckpt.get('history')\n",
                "    if hist is None:\n",
                "        continue\n",
                "    epochs = range(1, len(hist['train_loss']) + 1)\n",
                "\n",
                "    axes[0].plot(epochs, hist['train_loss'], label=f'{label} (train)')\n",
                "    axes[0].plot(epochs, hist['val_loss'], '--', label=f'{label} (val)')\n",
                "\n",
                "    axes[1].plot(epochs, hist['train_acc'], label=f'{label} (train)')\n",
                "    axes[1].plot(epochs, hist['val_acc'], '--', label=f'{label} (val)')\n",
                "\n",
                "    axes[2].plot(epochs, hist['train_mae'], label=f'{label} (train)')\n",
                "    axes[2].plot(epochs, hist['val_mae'], '--', label=f'{label} (val)')\n",
                "\n",
                "for ax, title in zip(axes, ['Loss', 'Classification Accuracy', 'Mass MAE (GeV)']):\n",
                "    ax.set_title(title)\n",
                "    ax.set_xlabel('Epoch')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "t0u1v2w3",
            "metadata": {},
            "source": [
                "<a id='9-discussion'></a>\n",
                "## 9. Discussion\n",
                "\n",
                "### Why SimCLR Over MAE for Sparse Calorimeter Data\n",
                "\n",
                "MAE pretraining was explored initially but yielded worse downstream performance than training from scratch (86.05% vs 89.45% accuracy). Two factors explain this:\n",
                "\n",
                "1. **Sparsity-dominated reconstruction:** With 98.8% of pixels being zero, the MAE decoder learns primarily to output zeros. The resulting backbone features are optimized for background reconstruction, not for distinguishing signal from background.\n",
                "\n",
                "2. **LCM incompatibility:** MAE requires masking patches and processing only visible tokens. Since masked tokens break the spatial grid, the Local Concentration Module (depthwise convolution) must be skipped during pretraining (`skip_lcm=True`). This means LCM weights remain randomly initialized when finetuning begins, injecting structured noise into the pretrained representations.\n",
                "\n",
                "SimCLR avoids both issues. Its contrastive objective learns discriminative features, and it processes all tokens through the full backbone (including LCM) at every step.\n",
                "\n",
                "### Physics Motivation for Augmentations\n",
                "\n",
                "The augmentation design follows from the symmetries and properties of the CMS detector:\n",
                "\n",
                "- **Cyclic translation in $\\phi$**: The CMS detector has cylindrical geometry, making the azimuthal angle periodic. A cyclic roll along the $\\phi$-axis is equivalent to observing the same collision from a rotated azimuthal perspective. This is consistent with the JetCLR approach (Dillon et al., 2022), which uses translations in the rapidity-azimuth plane as a physics-preserving augmentation.\n",
                "- **$\\eta$-flip**: Proton-proton collisions exhibit approximate forward-backward symmetry in pseudorapidity.\n",
                "- **Channel dropout**: CMS data spans multiple detector subsystems (tracker, ECAL, HCAL). Randomly zeroing 1-2 channels during pretraining encourages the model to learn features robust to partial detector information.\n",
                "- **Active-cell noise**: Real detector readouts contain electronic noise in active calorimeter cells. Noise is added only to non-zero pixels (`mask = img > 0`) to preserve the physical sparsity structure.\n",
                "\n",
                "### Finetuning Strategy\n",
                "\n",
                "Differential learning rates prevent catastrophic forgetting of pretrained features:\n",
                "\n",
                "| Component | Pretrained LR | Scratch LR |\n",
                "|---|---|---|\n",
                "| Backbone | 5e-5 | 3e-4 |\n",
                "| Task Heads | 1e-4 | 3e-4 |\n",
                "\n",
                "Both configurations use cosine annealing with 3-epoch warmup, AdamW optimizer (weight_decay=0.01), and gradient clipping (max_norm=1.0). Early stopping with patience=15 monitors the validation loss.\n",
                "\n",
                "### Reproducibility\n",
                "\n",
                "All experiments use deterministic splits (`seed=42`), the same model architecture, and identical training infrastructure. The only controlled variable between the pretrained and scratch experiments is the initialization: pretrained weights vs. random initialization.\n",
                "\n",
                "### References\n",
                "\n",
                "- [Zheng et al., \"L2ViT: The Linear Attention Resurrection in Vision Transformer\", arXiv:2501.16182, 2025.](https://arxiv.org/abs/2501.16182)\n",
                "- [Chen et al., \"A Simple Framework for Contrastive Learning of Visual Representations\", ICML, 2020.](https://arxiv.org/abs/2002.05709)\n",
                "- [Dillon et al., \"Symmetries, Safety, and Self-Supervision\", SciPost Physics 12, 188, 2022.](https://scipost.org/10.21468/SciPostPhys.12.6.188)\n",
                "- [He et al., \"Masked Autoencoders Are Scalable Vision Learners\", CVPR, 2022.](https://arxiv.org/abs/2111.06377)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
